{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os.path as osp\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import custom_dataloader\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision import models, transforms, torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchmetrics import F1Score, Precision, Recall, Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, stride=1, padding='same')\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3, stride=1, padding='same')\n",
    "        self.conv3 = nn.Conv2d(128, 256, 3, stride=1, padding='same')\n",
    "        self.conv4 = nn.Conv2d(256, 512, 3, stride=1, padding='same')\n",
    "        self.fc1 = nn.Linear(512 * 3 * 3, 512)\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv4(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 512 * 3 * 3)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics\n",
    "def eval_metrics(preds, targets, device):\n",
    "    f1_func = F1Score(task='binary', num_classes=2).to(device)\n",
    "    fl_score = f1_func(preds, targets)\n",
    "    \n",
    "    precision_func = Precision(task='binary', num_classes=2).to(device)\n",
    "    precision = precision_func(preds, targets)\n",
    "    \n",
    "    recall_func = Recall(task='binary', num_classes=2).to(device)\n",
    "    recall = recall_func(preds, targets)\n",
    "    \n",
    "    acc_func = Accuracy(task='binary', num_classes=2, top_k=1).to(device)\n",
    "    acc = acc_func(preds, targets)\n",
    "    \n",
    "    print(f'\\n F1-Score\\t : {fl_score} \\n Precision\\t : {precision} \\n Recall\\t\\t : {recall} \\n Accuracy\\t : {acc}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    targets, preds = torch.tensor([]).to(device), torch.tensor([]).to(device)\n",
    "    criterion =  nn.CrossEntropyLoss(reduction='sum') #add all samples in a mini-batch\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            test_loss +=  loss.item()\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "            flat_pred = pred.flatten().to(device)\n",
    "            flat_target = target.flatten().to(device)\n",
    "            \n",
    "            preds = torch.cat([preds, flat_pred])\n",
    "            targets = torch.cat([targets, flat_target])\n",
    "        \n",
    "    eval_metrics(preds=preds, targets=targets, device=device) # get metrics (F1, Accuracy, Precision, Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 62 # Image Size\n",
    "mean = (0.485, 0.456, 0.406) # 채널 별 평균 (Normalize)\n",
    "std = (0.229, 0.224, 0.225) # 표준편차 (Normalize)\n",
    "batch_size = 64\n",
    "\n",
    "### ImageFolder 작성\n",
    "test_imgs = ImageFolder(\"../test_dataset/\",\n",
    "                        transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                       transforms.Normalize(mean=mean, std=std)]))\n",
    "\n",
    "test_loader = data.DataLoader(test_imgs, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Device\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Evaluation metrics of CNN_9-46_338381.pt -----\n",
      "\n",
      " F1-Score\t : 0.9526351094245911 \n",
      " Precision\t : 0.9520000219345093 \n",
      " Recall\t\t : 0.9532710313796997 \n",
      " Accuracy\t : 0.959277331829071\n",
      "----- Evaluation metrics of CNN_9-50_12797.pt -----\n",
      "\n",
      " F1-Score\t : 0.9581239819526672 \n",
      " Precision\t : 0.9616677761077881 \n",
      " Recall\t\t : 0.9546061158180237 \n",
      " Accuracy\t : 0.9641525745391846\n",
      "----- Evaluation metrics of CNN_9-53_175500.pt -----\n",
      "\n",
      " F1-Score\t : 0.9602693319320679 \n",
      " Precision\t : 0.96875 \n",
      " Recall\t\t : 0.951935887336731 \n",
      " Accuracy\t : 0.966159999370575\n",
      "----- Evaluation metrics of CNN_9-23_201393.pt -----\n",
      "\n",
      " F1-Score\t : 0.954912543296814 \n",
      " Precision\t : 0.9626865386962891 \n",
      " Recall\t\t : 0.9472630023956299 \n",
      " Accuracy\t : 0.9615715742111206\n",
      "----- Evaluation metrics of CNN_9-68_444540.pt -----\n",
      "\n",
      " F1-Score\t : 0.9593003988265991 \n",
      " Precision\t : 0.9667796492576599 \n",
      " Recall\t\t : 0.951935887336731 \n",
      " Accuracy\t : 0.965299665927887\n"
     ]
    }
   ],
   "source": [
    "model_list = ['CNN_9-46_338381.pt', 'CNN_9-50_12797.pt', 'CNN_9-53_175500.pt', 'CNN_9-23_201393.pt', 'CNN_9-68_444540.pt']\n",
    "for m in model_list:\n",
    "    param = torch.load(f'./params/{m}')\n",
    "    net = CNN()\n",
    "    net.load_state_dict(param)\n",
    "    print(f'----- Evaluation metrics of {m} -----')\n",
    "    test(net, device=device, test_loader=test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
